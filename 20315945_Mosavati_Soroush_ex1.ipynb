{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soroushmosavati/MMAI/blob/NLP/20315945_Mosavati_Soroush_ex1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy0azQCVlCiR"
      },
      "source": [
        "# MMAI 894 - Exercise 1\n",
        "## Feedforward artificial neural network : Image classification\n",
        "The goal of this excercise is to show you how to create your first neural network using the tensorflow/keras library. We will be using the MNIST dataset.\n",
        "\n",
        "Submission instructions:\n",
        "- You cannot edit this notebook directly. Save a copy to your drive, and make sure to identify yourself in the title using name and student number\n",
        "- Do not insert new cells before the final one (titled \"Further exploration\")\n",
        "- Verify that your notebook can _restart and run all_.\n",
        "- Select File -> Download as .py (important! not as ipynb)\n",
        "- Rename the file: `studentID_lastname_firstname_ex1.py`\n",
        "- The mark will be assessed on the implementation of the functions with #TODO\n",
        "- **Do not change anything outside the functions**  unless in the further exploration section\n",
        "- The mark is not based on final accuracy - only on correctness\n",
        "- Note: You do not have to answer the questions in the notebook as part of your submission. They are meant to guide you.\n",
        "\n",
        "- You should not need to use any additional libraries other than the ones listed below. You may want to import additional modules from those libraries, however.\n",
        "\n",
        "References\n",
        "- https://keras.io/getting-started/sequential-model-guide/\n",
        "- https://keras.io/api/utils/python_utils/#to_categorical-function\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "- https://keras.io/api/layers/core_layers/dense/\n",
        "- https://keras.io/api/layers/regularization_layers/dropout/\n",
        "- https://keras.io/api/models/model_training_apis/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qp33aomJmJtl"
      },
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trOyfziVgETH"
      },
      "source": [
        "# Import modules\n",
        "# Add modules as needed\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# For windows laptops add following 2 lines:\n",
        "#import matplotlib\n",
        "#matplotlib.use('agg')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZmZEVmTmQGH"
      },
      "source": [
        "### Data preparation\n",
        "\n",
        "#### Import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gRy7rVvg_Sl"
      },
      "source": [
        "def load_data():\n",
        "    # Import MNIST dataset from openml\n",
        "    dataset = fetch_openml('mnist_784', version=1, data_home=None)\n",
        "\n",
        "    # Data preparation\n",
        "    raw_X = dataset['data']\n",
        "    raw_Y = dataset['target']\n",
        "    return raw_X, raw_Y\n",
        "\n",
        "raw_X, raw_Y = load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEwXHBQh8r93"
      },
      "source": [
        "## Consider the following\n",
        "- what shape is X?\n",
        "- what value ranges does X take?\n",
        " - might this present a problem?\n",
        " - what transformations need to be applied?\n",
        "- what shape is Y?\n",
        "- what value ranges does Y take?\n",
        " - what transformations should be applied?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT499lYakFjo"
      },
      "source": [
        "def clean_data(raw_X, raw_Y):\n",
        "    # TODO: clean, QA, and prep raw_X and raw_Y\n",
        "    # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTIONthanks\n",
        "    cleaned_X = keras.utils.normalize(raw_X, axis=-1 , order=2)\n",
        "    cleaned_Y = keras.utils.to_categorical(raw_Y, num_classes=10, dtype=\"float32\")\n",
        "\n",
        "    return cleaned_X, cleaned_Y\n",
        "\n",
        "cleaned_X, cleaned_Y = clean_data(raw_X, raw_Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gjkRpwbkP1j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb82e82b-ca16-4e55-816b-1ebb9801c94f"
      },
      "source": [
        "def split_data(cleaned_X, cleaned_Y):\n",
        "    # TODO: split the data into validation, test, and train datasets\n",
        "    # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\n",
        "    X_test, X_train, Y_test, Y_train= train_test_split(cleaned_X, cleaned_Y, test_size=0.50, random_state=0)\n",
        "    X_val, X_test, Y_val, Y_test = train_test_split(X_test, Y_test, test_size=0.60, random_state=0)\n",
        "\n",
        "    return X_val, X_test, X_train, Y_val, Y_test, Y_train\n",
        "\n",
        "X_val, X_test, X_train, Y_val, Y_test, Y_train = split_data(cleaned_X, cleaned_Y)\n",
        "print(X_val.shape, X_test.shape, X_train.shape, Y_val.shape, Y_test.shape, Y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14000, 784) (21000, 784) (35000, 784) (14000, 10) (21000, 10) (35000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpfxuSt4nKUw"
      },
      "source": [
        "#### Data split\n",
        "\n",
        "- Split your data into a train set (50%), validation set (20%) and a test set (30%). You may use scikit-learn's train_test_split function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGHlLLTanrUI"
      },
      "source": [
        "#### [Optional]: plot your data with matplotlib\n",
        "- Hint: you will need to reshape the row's data into a 28x28 matrix\n",
        "- https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.imshow.html\n",
        "- https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYpoQEMEkUhL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "aaab4ada-c6be-4c13-b381-ded7e0a39a49"
      },
      "source": [
        "def viz_data(X_train):\n",
        "    # TODO: (optional) plot your data with matplotlib\n",
        "    # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\n",
        "      plt.figure(figsize=(20,20))\n",
        "      for digits in range(0,10):\n",
        "          plt.subplot(1,10,digits+1)\n",
        "          grid = X_train.iloc[digits].to_numpy().reshape(28,28)\n",
        "          plt.imshow(grid, interpolation = \"none\", cmap = \"gray\")\n",
        "          plt.xticks([])\n",
        "          plt.yticks([])\n",
        "      plt.show()\n",
        "\n",
        "viz_data(X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x1440 with 10 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABG0AAABwCAYAAACkaY2RAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYOklEQVR4nO3df5jNZf7H8XvyYyUkzeymttiS9Es1qWTF+NFPlDKU5tLuXm2TaiXpqigZS7TVXsgqckWUVCIX6ZfLhZrWtIxSK0mJXCimJMRMON8/vte+e9+3+RxnzpzzOfc583z89frsfZ/P3NuZz5zjvu73fWdFIhEDAAAAAAAAvxyV6gEAAAAAAADgcEzaAAAAAAAAeIhJGwAAAAAAAA8xaQMAAAAAAOAhJm0AAAAAAAA8xKQNAAAAAACAh2pXpXNWVhbng6dIJBLJSsR9eA9TqiwSieQk4ka8j6nDs5gReBYzAM9iRuBZzAA8ixmBZzED8CxmhEqfRVbaAOHZlOoBADDG8CwCvuBZBPzAswj4odJnkUkbAAAAAAAADzFpAwAAAAAA4CEmbQAAAAAAADzEpA0AAAAAAICHmLQBAAAAAADwEJM2AAAAAAAAHmLSBgAAAAAAwENM2gAAAAAAAHiISRsAAAAAAAAPMWkDAAAAAADgISZtAAAAAAAAPFQ71QNIpr59+0pu165dYL/CwkLr+vvvv5fcu3dvycuXL7f6HTp0qLpDBABvHXPMMZJnzJgh+frrr7f6RSIRyVlZWYFtxcXFku+9916rX2lpafUGCwBAihQVFVnXw4cPD+y7dOlSyZ06dUrSiJBsc+fOlXzaaadJPu+881IxHGQ4VtoAAAAAAAB4iEkbAAAAAAAAD2XppetH7JyVFXvnkBx77LHW9fjx4yXr8qg6depU+2c99NBD1vWYMWOqfc9YRSKRrCP3OrJUvofNmzeXPGDAAMmDBw9O6s+tVauWZL2U0Rhj9uzZI7mgoCCp4zDGlEYikTaJuJGPz6Jr0KBBkkeMGCH573//u9VvwoQJksvLy5M/sGrKhGcxVnPmzJF83XXXSY5WAhVr244dO6x++vfg0UcfjXPEMatRz2KmqknPYgbjWcwANfVZ1CVR0cqhonE/M1OIZ/EI2rZta13/+9//llxWVib5t7/9bWhjctXUZzHDVPosstIGAAAAAADAQ0zaAAAAAAAAeCgtT4+qV6+eZL183xhjOnfuHNM9Dhw4IHny5MlW2/HHHy/5xhtvlOyWdehl/4899lhMP7cmu/XWWyW3bt1act26da1+FRUVCf252dnZkrt162a1zZo1K6E/C5XTpxC5z4o+UaikpCS0MeFwL7zwgnWtT4nS5UwdO3a0+n3++ecx3V//ve7Zs6fVpssTx44da7X9/PPPMd0f8IFbtn3nnXdKdsuBmzRpEtM9dQnF9OnTJbt/T2N9FgH4YcmSJZI5Scpv0cqeli1bFuJIUBOx0gYAAAAAAMBDTNoAAAAAAAB4iEkbAAAAAAAAD6XNnjaNGjWS/Prrr0uOVv+5evVqyZMmTbLa9D22b98eeA9dH+4e56f3ZBg3bpzVtn///sB71hR6byBj7Lp+XfPv1v+7RwFX1+jRowPbXnrppYT+LFRdy5YtJbOnTWq1atXKup47d67ke++9V/I333wT1/379esnecaMGVab3j/HHceqVavi+nlAWPTfsZkzZ1ptF154oeQPPvjAanvxxRcl6+fq4MGDVr9NmzZJ1t9n3Pvpz7tp06ZZbT/88EPw/wEYY+zvLZdeemnMr9PfW3r16hXYT+9NpPdFrAp9jzZtfj0V9vbbb7f6ffHFF3HdH0DV6eO/8f/0fpYdOnQI7Pfmm29a14cOHZK8detWyYWFhYH3eOutt+IZYlphpQ0AAAAAAICHmLQBAAAAAADwUNqUR02cOFFytJKoLVu2SM7Ly5O8a9euuH6uPub7gQcesNouvvhiyVdccYXVNn/+/Lh+XiapXdv+9dJlUOXl5ZLjXSIcq969e0vevHmz1aZL6JAaAwcOlKzLFo0xZvfu3WEPp8bJycmRnJ2dbbVNmTJFcrwlUZo+uvvdd9+12nRJgbuMlvIo+K5p06aSdTmUMcZ8/fXXkrt06WK1VVRUVPln6e8bd911l9U2cuRIyfo7ijHG9O/fX/LOnTur/HMzxdFHH21dX3755ZKnTp0quXHjxla/RJc2JfoeblnWmDFj4ro/YudumxAPjvlOH+eee651rZ+/5cuXhz0cL+Xn50vu3r275IKCgsDX6HIo9/qEE06QHO3f1k8//bRk92/rqFGjJJeVlQXew3estAEAAAAAAPAQkzYAAAAAAAAeYtIGAAAAAADAQ97uaePWvul9STS9h40xxlx11VWS493HJsgvv/xiXeu66KFDh1ptCxculOwe3QljPvvsM8l6n4tki1Y3ieQ56qhf54fd/+bnn3++ZPf4d/a0ST59VK0+1tttSzb9e3HGGWeE9nOBRGjYsGFgm947LZ49bFz6u8i4ceOstjVr1kju16+f1aZr/nXbgQMHqj2mdDJkyBDr2v3+lq5yc3Ota/07yWdp4hQVFaV6CAhRq1atJLt7m86dO1dySUlJaGPyWfv27SVH28cm0f72t79Jdv+dofeZu+GGG6y2ML/nVhcrbQAAAAAAADzEpA0AAAAAAICHvCqP0kdEDxs2zGqrW7dupa/RR2kaY8zgwYMl6yO+NmzYUO3xTZo0ybq+//77JbtHa+pyEMqjDvf5559LDrM86ttvv416jeTQSxWjHXParVs363ry5MlJGxMO5x65HiZ9jG1NoD/v9PLrjRs3Wv30cZe///3vEzqGOnXqWNfXXHNNTK/Tfzefe+45qy2dj9Osjq5duwa2zZ49O7RxLFq0SPLSpUutNl0y3rdvX8kzZ860+mV62bBbVr948WLJ7pHsifbggw9K1t8hdUn9kbhlb/+j/1YYU/PK3tLJiBEjUj0ExOiiiy6S3KBBA6tt//79YQ/He++//77kRo0aSW7durXV77333pPsfv/r0KFD4Ovi0bZtW8lueay7LYDPWGkDAAAAAADgISZtAAAAAAAAPORVeZQuKWrZsmVMr9G7VLvXmzdvljx8+PBqjg6JpMsB6tevb7WFWS6F5Fm/fn2VX9OiRYskjATpQJfN6fLJTPXpp59KPvXUUyW7y611afBvfvMbq00vKY5WdhhEf0YaY0xpaWlMr7vzzjsl33333VbbSSedVOVxZAJdWuj+N/npp5/CHo4x5vATL8ePHy95+vTpkt955x2r3/bt25M7sBRzy26ff/55ye4Jhpp+3q6++mqr7cwzz5Tcpk0byW5ZvT5tRpcW/vDDD0cY9a+CyqP27NljXe/bty/meyJ2HTt2rPY93NJF+Cs/Pz+wbcKECSGOJD3MmTNH8ttvvy355JNPtvpF+56n/43YrFkzyd27d7f69e/fv8rju/baa61rXR4c63egVGGlDQAAAAAAgIeYtAEAAAAAAPAQkzYAAAAAAAAe8mpPG/fY7Hg89NBDkp966qlq308rLy9P6P1qsqefflpymHvYfP/996H9rJpu27ZtqR4CPHbZZZdZ16tWrZKs997IVLfddpvkV155RbLea8QYY/7zn/9Ido/k1m1LliyR7B67rY96ToRp06ZJ7tmzZ0LvnYkGDx4suSpHOyea3n+hV69egf3OOeccyX/4wx+stgULFiR+YCmmv9vFup+P3gcnXlXZx0bT+z/q49ndY3ORHHl5eVV+jbuHDXva+Ov888+3rq+88krJy5cvt9pWrFgRxpDS1t69eyVXZa9C3Vdnd/+1AQMGSNZ7ib366qtWP70vjvuZpr9HXXLJJZJXrlwZ83jDwkobAAAAAAAADzFpAwAAAAAA4CGvyqP0sqRYbdq0ybrWRyjqZVmJMH/+fOt62LBhCb1/prnhhhsC25o0aSLZPX5NH4+ql5DqY3GNsY8Kb9SokdWWm5sruV69epJfeumlI4waiaKPzhs3bpzke+65J/A1LO/ObLp81S2rqQnHfGvFxcWS9THAY8eOtfrt2LFD8rx585I+rljov71fffVVCkfiD/37u2bNGqvt9NNPl+weKZ3o0rVotm7dKrl9+/aSdbmyMfaz6f5N1scd699hJI97rLAuiYpEIpVm+GXZsmWpHgJi9PDDD1vXdevWleyWRfLM+UOXM7n/Xr/rrrtiusfw4cMl9+jRIzEDSyBW2gAAAAAAAHiISRsAAAAAAAAPeVUeFQ939/1Yd/6PR+/evZN270xx4403Sh41alRgv3/84x+Bbb/88ovkLVu2SHZLoOrUqSO5dm37V1lf65MW3NIDPcZnnnnGavvnP/8ZOEbEL9py0qZNm4Y4EoQhJydH8siRIyXrsh9jjOnXr19oY/KNPu3piSeesNoKCwslV1RUhDYmV4MGDSSfd955kjdu3JiC0fjnu+++k+x+9s2aNUvy6tWrrbauXbtK/vLLL5M0usN17txZcrRS5k8++cS6/vDDD5M2JvzqxBNPlNy3b98UjgTIfPrkoe7du1tt+nShqVOnhjYmxM/9DL7wwgslt23bNvB1+ntO48aNrbYff/wxIWOrDlbaAAAAAAAAeIhJGwAAAAAAAA8xaQMAAAAAAOChtN/TRtfWG2PXqpWUlIQ9nBqvYcOGkt16wFgFHfvsHpWqj+HTR2BGo488NcauUVy+fHmMI0RVrV+/PqZ+F1xwQZJHgrDNmDFDst7PaPTo0Va/mnbkt6aPzdZHThpjzLp16ySPGTMmtDHp2m5jjPnrX/8quWXLlpIPHjxo9dP7hnXq1Mlq03/D33jjDckDBgyo3mA94x7v+9prr0nOz8+32lasWCF56NChkidNmmT1S/TRsu44tEWLFkm+4447rDa95xySp0uXLpLj/S6FxMjLy0v1EJAELVq0kKz/RpeXl1v9hgwZItn9vIOf9D6Bxhjzl7/8RfLatWsDX9ehQwfJBQUFVtvEiRMTNLr4sdIGAAAAAADAQ0zaAAAAAAAAeMir8ii3dCUW+jhnY4ypVatWooaDOOgjuhcvXhzTa9zl1o8//rhkvcxcLxc2xpj69etLbt26tdU2YsQIybt27ZJcVFRk9SsuLpa8c+fOmMaLqlu4cKHkf/3rX4H99DGnSE+DBg2yrnNzcyWvWrVK8syZM0Mbk+/mzZsn2T1SWZcOjR8/3mr7+eefY7p/dna25Pbt20u+7rrrAl/TpEkT67pHjx6V9jvuuOOs64EDB0p2S94++ugjye7R15nk22+/ta71cfa6LMwY+/NOL792y5LmzJkjWS/l18u5jbFLadyyjkaNGkm+6KKLgoZvlWlt2LAhsB/8okvtkDiUR2WGOnXqWNe6lPeUU06RvGDBAqvfkiVLkjswJN22bdsku6XH/fv3r/Q1t99+u3U9d+7cSu8XJlbaAAAAAAAAeIhJGwAAAAAAAA8xaQMAAAAAAOAhr/a00TXb8e53cNZZZ0n+4IMPqj0m7aabbkro/TLRW2+9VWlOhGh75ETb22Hq1KmS3VpVhC/oSHdj7CPjkTg5OTnW9fXXX1/le7Rq1Srwfvo4YveYRN3Wq1cvye6RjDXZnj17JF966aUJv79+76ZNmyb5m2++sfrpPYdc+rmdPXu25D59+iRiiBlNHyH78ssvW23vvvuu5P/+97+S3f29hg0bJtk9Fl47dOiQ5I8//thqmz59uuQLLrhA8vr1661+a9asCbw/wud+Zuq9HPU+V4888khoYwLSjd7TyxhjunXrJvmnn36SPHLkyNDGhHDs3btXsvt5p/+e6nz22Wdb/fQ+qqnCShsAAAAAAAAPMWkDAAAAAADgIa/Ko/TRz82aNbPa9JFrp556auA9OnfuLHnKlCnVHlOnTp0kRzuO2D2mVS9RRvK1a9cusM09YhWppctlkDyFhYWS3SMO9Xugl967701Qm7tcP1qb1rx5c8n79u2z2s4880zJ+mhFY2I/2hqVKy4uluwe0R1El7IZYx/5rcujUDUVFRXWtT4eXB/N7tLfRfLz8yXv2LHD6qefFX2cuDHGvPLKK5Lr1q0r2f2M3L9/f+A4EA79u+D+XdbfL/k8Tb6OHTumegiIk/4+ct999wX201tyrFy5MqljQmpF+3say/+eSqy0AQAAAAAA8BCTNgAAAAAAAB7yqjxKL1navHmz1fbnP/9Z8sSJEyWfe+65Vr/27dtLPvbYYyXv2rUr5nE0btxY8rPPPiu5dm37P5dedjd69Gir7eDBgzH/PMSnXr16krt27RrYb8WKFWEMB0gpfUKQMcYMGTJEsrscVJcfzZs3T/LatWsD769PnBo6dKjVFm2Jvm7Tp9e4r1m3bl2l40N4dMnM/fffb7Vt3LhRMqfwhU+XiOscjT4Jw5jgEm9dogU/3HLLLTH1Ky0tTfJIkJeXl+ohIE65ubmSH3jgAatNn9r42GOPhTYmpKemTZtK/uqrr1IyBlbaAAAAAAAAeIhJGwAAAAAAAA8xaQMAAAAAAOAhr/a0iUYfWTpr1izJ7p42J510kuQnn3xS8m233RZ476OPPtq61sdinnbaaYGv08d8L1q0KLAfkuOee+6R/Mc//tFqmz9/vuTy8vKwhgSkTEFBgXV9yimnSNb7xRhjzJ/+9CfJ0Y7THjRokGR9hLh7rHdZWZnk3/3ud1ab3gsnJydH8meffWb103/jkRr6iMv69etbbXpPG46ETg8333yzde1+Tv6P/i4DAJli4cKFgW0lJSWS3X1UAVePHj0kp+r7KittAAAAAAAAPMSkDQAAAAAAgIfSpjxKGzt2rOQuXbpYbfr61ltvlXzCCSdY/b744gvJetm/McYcc8wxlf5c9xjv119/XTLLxcPnlmFoW7Zskczx66m3e/duyV9++aXVdvrpp4c9nIykj+42xj7y+4wzzrDa9PHgDRo0kNyzZ0+r38CBAyXrI7onT55s9ZsyZUrguPTfSfjtwIEDkt3l4vXq1Qt7OKimXr16Bbbp70CffPJJGMNBFM2bN7eus7OzA/vqkla3zBR+KioqSvUQagz9/eb4448P7Pfaa6+FMRxkiGeffTbVQ2ClDQAAAAAAgI+YtAEAAAAAAPAQkzYAAAAAAAAeSss9bfQRzvn5+Vbbyy+/LPnKK6+U3K1bN6ufex1E740yYcIEq+3xxx+P6R5IDl2runbtWqvtkUceCXs4iKJhw4aSW7RoYbXpvVJcJ554ouStW7cmfmAZpLS01LpetGiR5KuuuspqW7FihWR9fLf7Xuh9TfTx3+xTk/ncz7s333xT8h133CHZ3Utp27ZtSR0XYldRURHY9uKLL0rWe6QgNVq2bGld688+1549eySvWrUqaWMC0lHbtm0l16pVS7Les80YYz788MPQxgR/6O+8xhhz1FFHVZp95PfoAAAAAAAAaigmbQAAAAAAADyUluVR2q5du6zrPn36SL722mslP/zww1Y/fQTuvn37rLZRo0ZJnjp1quTvvvuueoNFQhUUFEhevHix1bZz586wh4MkyM3NlUx5VNU8+uijkq+44gqrTZdBvf/++5LdsqeZM2dKLisrS/QQ4TH9e2GMMXl5eZX2oxzKXwsXLrSue/fuLbljx46S9XcepIZbwhqtbHj79u3JHg6UTp06WddLliyRvHTpUsnLli2z+uk2hKddu3aSdSnMunXrrH6rV68ObUzwh/u39dChQ5X2mz17tnXtw3dgVtoAAAAAAAB4iEkbAAAAAAAAD6V9eZRr9+7dkvXSfp2ReT7++ONUDwFR6BIKdym+Ll2cMmWK1fbGG28kd2AZrLi4WLI+QQGIhT6hxpjDl/4DSJyzzjor5r4lJSWSmzZtKplSxeRwy5zc02fgl8LCwkozUBVuibi7HUsqsNIGAAAAAADAQ0zaAAAAAAAAeIhJGwAAAAAAAA9l3J42qDnYpyN9HDhwQHJRUZHV5l4DAKpvw4YN1vV7770necaMGWEPBwmSm5sruU+fPpLHjx+fiuEAAELAShsAAAAAAAAPMWkDAAAAAADgIcqjAAAAMkxxcbF1nZeXl5qB4IgefPBB6/rtt9+WnJ2dbbXp93Hv3r1JHRcA1BQrV66UvGDBghSOpHKstAEAAAAAAPAQkzYAAAAAAAAeYtIGAAAAAADAQ1mRSCT2zllZsXdGQkUikaxE3If3MKVKI5FIm0TciPcxdXgWMwLPYgbgWcwIPIsZgGcxI/AsZgCexYxQ6bPIShsAAAAAAAAPMWkDAAAAAADgoaoe+V1mjNmUjIEgqmYJvBfvYerwPqY/3sPMwPuY/ngPMwPvY/rjPcwMvI/pj/cwM1T6PlZpTxsAAAAAAACEg/IoAAAAAAAADzFpAwAAAAAA4CEmbQAAAAAAADzEpA0AAAAAAICHmLQBAAAAAADwEJM2AAAAAAAAHmLSBgAAAAAAwENM2gAAAAAAAHiISRsAAAAAAAAP/R/XKVsVwtOunAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRTFvCTzn12X"
      },
      "source": [
        "### Model\n",
        "\n",
        "#### Neural network structure\n",
        "- For this network, we'll use 2 hidden layers\n",
        "- Layer 1 should have 128 nodes, a dropout rate of 20%, and relu as its activation function\n",
        "- Layer 2 should have 64 nodes, a dropout rate of 20%, and relu as its activation function\n",
        "- The last layer should map back to the 10 possible MNIST class. Use softmax as the activation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgoOjxY9ki_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eac85a51-705f-4f27-bfd3-be5bd1f415ea"
      },
      "source": [
        "def build_model():\n",
        "    # TODO: build the model,\n",
        "    # HINT: you should have Total params: 109,386\n",
        "    # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\n",
        "\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.Input(shape=(784,)))\n",
        "    model.add(keras.layers.Dense(128, activation=\"relu\"))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(keras.layers.Dense(64, activation=\"relu\"))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "    return model\n",
        "\n",
        "model = build_model()\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               100480    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109,386\n",
            "Trainable params: 109,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqv4in2ZodVR"
      },
      "source": [
        "# Model compilation\n",
        "\n",
        "- what loss function should you use?\n",
        "- Note your choice of optimizer\n",
        "- Include accuracy as a metric (why are we using accuracy here?)\n",
        "\n",
        "# Model training\n",
        "- Use a batch size of 128, and train for 12 epochs\n",
        "- Use verbose training, include validation data\n",
        "\n",
        "More information: https://keras.io/api/models/model_training_apis/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHD6wIDlk095",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12ce47cc-86a7-411c-a2bd-bb43e284c009"
      },
      "source": [
        "def compile_model(model):\n",
        "    # TODO: compile the model\n",
        "    # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\n",
        "    model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def train_model(model, X_train, Y_train, X_val, Y_val):\n",
        "    history = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), verbose=1 , epochs=12 , batch_size=128)\n",
        "    return model, history\n",
        "\n",
        "\n",
        "model = compile_model(model)\n",
        "model, history = train_model(model, X_train, Y_train, X_val, Y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "274/274 [==============================] - 7s 6ms/step - loss: 0.8664 - accuracy: 0.7520 - val_loss: 0.3340 - val_accuracy: 0.9041\n",
            "Epoch 2/12\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 0.3593 - accuracy: 0.8931 - val_loss: 0.2471 - val_accuracy: 0.9270\n",
            "Epoch 3/12\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 0.2787 - accuracy: 0.9185 - val_loss: 0.2001 - val_accuracy: 0.9412\n",
            "Epoch 4/12\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 0.2338 - accuracy: 0.9306 - val_loss: 0.1719 - val_accuracy: 0.9486\n",
            "Epoch 5/12\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 0.1971 - accuracy: 0.9422 - val_loss: 0.1498 - val_accuracy: 0.9571\n",
            "Epoch 6/12\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 0.1731 - accuracy: 0.9487 - val_loss: 0.1353 - val_accuracy: 0.9608\n",
            "Epoch 7/12\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 0.1583 - accuracy: 0.9528 - val_loss: 0.1250 - val_accuracy: 0.9639\n",
            "Epoch 8/12\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 0.1423 - accuracy: 0.9582 - val_loss: 0.1152 - val_accuracy: 0.9669\n",
            "Epoch 9/12\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 0.1277 - accuracy: 0.9615 - val_loss: 0.1079 - val_accuracy: 0.9692\n",
            "Epoch 10/12\n",
            "274/274 [==============================] - 2s 8ms/step - loss: 0.1172 - accuracy: 0.9649 - val_loss: 0.1058 - val_accuracy: 0.9697\n",
            "Epoch 11/12\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 0.1088 - accuracy: 0.9670 - val_loss: 0.0993 - val_accuracy: 0.9708\n",
            "Epoch 12/12\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 0.0993 - accuracy: 0.9693 - val_loss: 0.0943 - val_accuracy: 0.9717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6wzs18_ormL"
      },
      "source": [
        "# Model evaluation\n",
        "- Show the performance on the test set\n",
        "- What is the difference between \"evaluate\" and \"predict\"?\n",
        "- Identify a few images the model classifies incorrectly. Any observations?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxrqJb9Uk3Hz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0654ec2f-1795-446b-9af7-fdd5eede1ef3"
      },
      "source": [
        "def eval_model(model, X_test, Y_test):\n",
        "    # TODO: evaluate the model\n",
        "    # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\n",
        "\n",
        "    score = model.evaluate(X_test, Y_test, verbose=1)\n",
        "    test_accuracy=print('Test accuracy:', score[1])\n",
        "    test_loss=print('Test loss:', score[0])\n",
        "\n",
        "    return test_loss, test_accuracy\n",
        "\n",
        "test_loss, test_accuracy = eval_model(model, X_test, Y_test)\n",
        "\n",
        "print('Result:', test_loss, test_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "657/657 [==============================] - 2s 3ms/step - loss: 0.0946 - accuracy: 0.9716\n",
            "Test accuracy: 0.9715714454650879\n",
            "Test loss: 0.09455550462007523\n",
            "Result: None None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u21sXyjWpnPX"
      },
      "source": [
        "Further exploration (Not evaluated)\n",
        "Looking for something else  to do?\n",
        "- Transform your code to do hyperparameter search.\n",
        "- You can vary the number of nodes in the layers, the drop out rate, the optimizer and the parameters in Adam, the batch size, etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing a sample of prediction\n",
        "from matplotlib.spines import np\n",
        "Y_Predict = model.predict(X_test)\n",
        "Y_Predict = np.argmax(Y_Predict, axis=1)\n",
        "print(\"Predicted Number is:\", Y_Predict[50])\n",
        "\n",
        "print(\"Original Number is:\")\n",
        "\n",
        "Pred_grid = X_test.iloc[50].to_numpy().reshape(28,28)\n",
        "plt.imshow(Pred_grid, interpolation = \"none\", cmap = \"gray\")\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "d1D6Kok6qget",
        "outputId": "4ffa0e1d-f1f7-41d6-a485-071eee89326f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "657/657 [==============================] - 1s 2ms/step\n",
            "Predicted Number is: 8\n",
            "Original Number is:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test_rev= np.argmax(Y_test, axis=1)\n",
        "\n",
        "print('')\n",
        "print(\"List of incorrect prediction:\")\n",
        "print('')\n",
        "incorrects = np.nonzero(Y_Predict.reshape((-1,)) != Y_test_rev)\n",
        "\n",
        "print(incorrects)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bp1_1jOi4EEu",
        "outputId": "292f7eb4-cfbb-4bba-c0eb-a564ab384b5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "List of incorrect prediction:\n",
            "\n",
            "(array([   23,    41,    61,    98,   158,   187,   300,   338,   351,\n",
            "         405,   508,   509,   539,   548,   571,   621,   622,   636,\n",
            "         661,   679,   702,   784,   796,   808,   843,   894,   905,\n",
            "         918,   933,   943,  1042,  1112,  1212,  1233,  1254,  1292,\n",
            "        1330,  1384,  1394,  1399,  1415,  1510,  1537,  1556,  1565,\n",
            "        1576,  1612,  1616,  1627,  1655,  1673,  1711,  1729,  1787,\n",
            "        1805,  1819,  1880,  1908,  1985,  2074,  2099,  2106,  2120,\n",
            "        2131,  2148,  2152,  2183,  2223,  2241,  2246,  2277,  2297,\n",
            "        2421,  2501,  2533,  2559,  2571,  2627,  2648,  2651,  2730,\n",
            "        2739,  2746,  2813,  2861,  2893,  2933,  2936,  2961,  2978,\n",
            "        3020,  3049,  3071,  3076,  3085,  3111,  3131,  3178,  3192,\n",
            "        3289,  3310,  3360,  3368,  3391,  3418,  3424,  3452,  3491,\n",
            "        3754,  3821,  3845,  3868,  3914,  3975,  3991,  4018,  4070,\n",
            "        4087,  4108,  4118,  4138,  4152,  4179,  4236,  4267,  4276,\n",
            "        4316,  4334,  4345,  4429,  4454,  4460,  4467,  4524,  4529,\n",
            "        4555,  4637,  4683,  4704,  4836,  4843,  4850,  4867,  4948,\n",
            "        4966,  4997,  5001,  5038,  5085,  5227,  5282,  5297,  5306,\n",
            "        5333,  5360,  5517,  5572,  5610,  5618,  5646,  5671,  5693,\n",
            "        5722,  5738,  5775,  5831,  5884,  5907,  5950,  5951,  5965,\n",
            "        5986,  6039,  6043,  6074,  6108,  6128,  6156,  6226,  6272,\n",
            "        6498,  6511,  6542,  6547,  6559,  6615,  6632,  6647,  6717,\n",
            "        6749,  6777,  6791,  6793,  6819,  6823,  6832,  6842,  6865,\n",
            "        6904,  6960,  7000,  7018,  7036,  7089,  7122,  7164,  7179,\n",
            "        7190,  7217,  7247,  7274,  7321,  7336,  7421,  7448,  7451,\n",
            "        7530,  7567,  7608,  7682,  7856,  7869,  7916,  7957,  7963,\n",
            "        8080,  8081,  8082,  8186,  8197,  8211,  8219,  8230,  8354,\n",
            "        8359,  8416,  8417,  8467,  8494,  8523,  8562,  8615,  8707,\n",
            "        8710,  8724,  8773,  8828,  8846,  8870,  8916,  8954,  8973,\n",
            "        9037,  9055,  9090,  9096,  9276,  9317,  9332,  9395,  9409,\n",
            "        9412,  9425,  9434,  9437,  9690,  9707,  9722,  9740,  9750,\n",
            "        9774,  9777,  9801,  9843,  9882,  9940,  9946, 10044, 10063,\n",
            "       10113, 10124, 10142, 10229, 10235, 10251, 10262, 10364, 10399,\n",
            "       10460, 10487, 10578, 10672, 10716, 10731, 10790, 10803, 10832,\n",
            "       10861, 10951, 10979, 11045, 11154, 11163, 11196, 11228, 11247,\n",
            "       11250, 11267, 11276, 11290, 11345, 11351, 11391, 11409, 11436,\n",
            "       11476, 11485, 11513, 11542, 11557, 11585, 11630, 11703, 11708,\n",
            "       11804, 11837, 11846, 11852, 11879, 11888, 11928, 11936, 11943,\n",
            "       11944, 11946, 11951, 11957, 11980, 11981, 11992, 11999, 12020,\n",
            "       12042, 12046, 12093, 12178, 12187, 12204, 12210, 12274, 12284,\n",
            "       12287, 12295, 12335, 12345, 12370, 12426, 12518, 12561, 12581,\n",
            "       12628, 12688, 12722, 12795, 12885, 13002, 13101, 13163, 13220,\n",
            "       13264, 13265, 13273, 13281, 13285, 13353, 13399, 13401, 13403,\n",
            "       13417, 13452, 13470, 13561, 13664, 13690, 13831, 13931, 14035,\n",
            "       14066, 14081, 14086, 14186, 14250, 14259, 14261, 14298, 14397,\n",
            "       14402, 14431, 14435, 14468, 14576, 14669, 14696, 14705, 14802,\n",
            "       14826, 14835, 14865, 14901, 14944, 14959, 14970, 15006, 15020,\n",
            "       15059, 15087, 15114, 15132, 15201, 15211, 15260, 15269, 15305,\n",
            "       15348, 15419, 15502, 15575, 15641, 15684, 15793, 15924, 15977,\n",
            "       15990, 16004, 16011, 16019, 16041, 16050, 16133, 16263, 16274,\n",
            "       16367, 16380, 16388, 16515, 16530, 16531, 16573, 16587, 16591,\n",
            "       16605, 16621, 16650, 16662, 16739, 16807, 16828, 16864, 16872,\n",
            "       16958, 16979, 16985, 17003, 17010, 17012, 17014, 17042, 17045,\n",
            "       17070, 17079, 17090, 17115, 17158, 17170, 17190, 17221, 17324,\n",
            "       17406, 17409, 17412, 17442, 17458, 17520, 17523, 17603, 17814,\n",
            "       17854, 17893, 17993, 18022, 18043, 18057, 18119, 18136, 18164,\n",
            "       18176, 18187, 18214, 18226, 18229, 18243, 18264, 18316, 18332,\n",
            "       18427, 18429, 18431, 18480, 18558, 18567, 18585, 18602, 18605,\n",
            "       18612, 18621, 18650, 18682, 18699, 18700, 18706, 18755, 18885,\n",
            "       18937, 18942, 18990, 19048, 19051, 19060, 19070, 19099, 19102,\n",
            "       19103, 19105, 19120, 19176, 19179, 19191, 19261, 19270, 19278,\n",
            "       19319, 19329, 19359, 19386, 19402, 19462, 19494, 19501, 19523,\n",
            "       19585, 19612, 19639, 19652, 19660, 19668, 19674, 19684, 19685,\n",
            "       19720, 19759, 19782, 19795, 19817, 19859, 19903, 19907, 19948,\n",
            "       19969, 19974, 19986, 20012, 20067, 20089, 20122, 20270, 20304,\n",
            "       20351, 20354, 20359, 20401, 20442, 20481, 20549, 20565, 20572,\n",
            "       20593, 20603, 20633, 20672, 20859, 20873, 20874, 20882, 20937,\n",
            "       20938, 20949, 20971]),)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Displaying a sample of incorrect prediction\n",
        "Pred_grid = X_test.iloc[16515].to_numpy().reshape(28,28)\n",
        "plt.imshow(Pred_grid, interpolation = \"none\", cmap = \"gray\")\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.show()\n",
        "print('')\n",
        "print(\"The predicted digit was:\")\n",
        "print(Y_Predict[16515])\n",
        "print('')\n",
        "print(\"The correct digit was:\")\n",
        "Y_Cor = Y_test[16515]\n",
        "Y_Cor = np.argmax(Y_Cor, axis=0)\n",
        "print(Y_Cor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "7AYMl2_UqcXp",
        "outputId": "edf95f5a-ae1f-4ad8-e726-5dc68941cd61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The predicted digit was:\n",
            "6\n",
            "\n",
            "The correct digit was:\n",
            "0\n"
          ]
        }
      ]
    }
  ]
}