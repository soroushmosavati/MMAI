{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soroushmosavati/MMAI/blob/main/Leaves_Disease_SM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcOkx-wT_kBa"
      },
      "source": [
        "# Environement Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwG3DKN--oFy",
        "outputId": "e137767b-84f4-440c-b6ff-b3220d9106b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2 as cv\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, Activation\n",
        "\n",
        "import zipfile\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHQFAl-9_usK"
      },
      "source": [
        "# Data Prepration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOw3A_a4_zmA",
        "outputId": "8ef0b2d2-5ded-433c-c09a-c3df82c672bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['algal leaf',\n",
              " 'white spot',\n",
              " 'healthy',\n",
              " 'gray light',\n",
              " 'bird eye spot',\n",
              " 'Anthracnose',\n",
              " 'red leaf spot',\n",
              " 'brown blight']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#Loading Dataset and listing Category labels\n",
        "data_dir = \"/content/gdrive/MyDrive/Colab Notebooks/tea sickness dataset/\"\n",
        "class_names = os.listdir(data_dir)\n",
        "class_names"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')"
      ],
      "metadata": {
        "id": "r8S20_zbQ_qD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(256, 256),\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    class_mode='categorical')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "dNtiJL8LVEVI",
        "outputId": "147446f2-6844-4cf7-cb48-04c01cdba87b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-d870dadc7e3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_generator = datagen.flow_from_directory(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: flow_from_directory() got an unexpected keyword argument 'validation_split'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0M4puBV8RuC",
        "outputId": "00d73a05-f40a-42b6-ac2e-53ffe7690246"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 885 files belonging to 8 classes.\n",
            "Using 177 files for validation.\n"
          ]
        }
      ],
      "source": [
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUxSLt9G8p40",
        "outputId": "4ddd440c-e1b9-42e4-e863-f3e7e560e2a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(16, 256, 256, 3)\n",
            "(16,)\n"
          ]
        }
      ],
      "source": [
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwTeSqaeELX_"
      },
      "outputs": [],
      "source": [
        "image_batch = tf.cast(tf.expand_dims(image_batch, 0), tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxlAQud676pI",
        "outputId": "1e58a587-fb35-410e-bbe0-20a75316e7cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 885 files belonging to 8 classes.\n",
            "Using 708 files for training.\n"
          ]
        }
      ],
      "source": [
        "batch_size = 16\n",
        "img_height = 256\n",
        "img_width = 256\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvi5-ddL82ju",
        "outputId": "c5b240d3-6d8d-441e-feac-b83f14f26e81"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.008501839 0.99644613\n"
          ]
        }
      ],
      "source": [
        "normalization_layer = layers.Rescaling(1./255)\n",
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\n",
        "first_image = image_batch[0]\n",
        "# Notice the pixel values are now in `[0,1]`.\n",
        "print(np.min(first_image), np.max(first_image))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97bZmlNNhDL8"
      },
      "source": [
        "# Build Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IC3l0XiZRYy-",
        "outputId": "5a4c4dc8-d3e3-47a8-c368-cc202b3050f8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential (Sequential)     (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 256, 256, 16)      208       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 128, 128, 16)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 128, 128, 32)      2080      \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 64, 64, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 64, 64, 64)        8256      \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 32, 32, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32, 32, 128)       8320      \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 131072)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 131072)            0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 8)                 1048584   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,067,448\n",
            "Trainable params: 1,067,448\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def build_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Input(shape=(256, 256, 3)), # Define the input shape\n",
        "        # Define the model architecture\n",
        "        tf.keras.layers.Conv2D(16, 2, padding='same', activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2),\n",
        "        tf.keras.layers.Conv2D(32, 2, padding='same', activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2),\n",
        "        tf.keras.layers.Conv2D(64, 2, padding='same', activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dropout(0.1),\n",
        "        tf.keras.layers.Dense(8)\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "model = build_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "uufXoVMzMIV3",
        "outputId": "7dc9a8b3-bb54-4864-f74f-78739b7b0d18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "45/45 [==============================] - 109s 2s/step - loss: 256.2315 - accuracy: 0.2542 - val_loss: 10.0964 - val_accuracy: 0.3333\n",
            "Epoch 2/20\n",
            "45/45 [==============================] - 104s 2s/step - loss: 4.8948 - accuracy: 0.4209 - val_loss: 1.8961 - val_accuracy: 0.4463\n",
            "Epoch 3/20\n",
            "45/45 [==============================] - 94s 2s/step - loss: 1.2372 - accuracy: 0.5876 - val_loss: 2.8056 - val_accuracy: 0.4802\n",
            "Epoch 4/20\n",
            "45/45 [==============================] - 101s 2s/step - loss: 1.2094 - accuracy: 0.5636 - val_loss: 1.5706 - val_accuracy: 0.5367\n",
            "Epoch 5/20\n",
            "45/45 [==============================] - 115s 2s/step - loss: 0.8143 - accuracy: 0.6850 - val_loss: 1.4327 - val_accuracy: 0.4520\n",
            "Epoch 6/20\n",
            "45/45 [==============================] - 96s 2s/step - loss: 0.8201 - accuracy: 0.6808 - val_loss: 1.4825 - val_accuracy: 0.4463\n",
            "Epoch 7/20\n",
            "45/45 [==============================] - 87s 2s/step - loss: 0.7963 - accuracy: 0.6893 - val_loss: 1.4961 - val_accuracy: 0.5311\n",
            "Epoch 8/20\n",
            "45/45 [==============================] - 98s 2s/step - loss: 0.8034 - accuracy: 0.6907 - val_loss: 1.3306 - val_accuracy: 0.5819\n",
            "Epoch 9/20\n",
            "45/45 [==============================] - 89s 2s/step - loss: 0.5937 - accuracy: 0.7641 - val_loss: 1.8174 - val_accuracy: 0.4576\n",
            "Epoch 10/20\n",
            "45/45 [==============================] - 89s 2s/step - loss: 0.7908 - accuracy: 0.6850 - val_loss: 1.2992 - val_accuracy: 0.5593\n",
            "Epoch 11/20\n",
            "45/45 [==============================] - 89s 2s/step - loss: 0.6206 - accuracy: 0.7768 - val_loss: 1.4269 - val_accuracy: 0.4633\n",
            "Epoch 12/20\n",
            "45/45 [==============================] - 86s 2s/step - loss: 0.5768 - accuracy: 0.7782 - val_loss: 1.1910 - val_accuracy: 0.5480\n",
            "Epoch 13/20\n",
            "45/45 [==============================] - 95s 2s/step - loss: 0.6238 - accuracy: 0.7782 - val_loss: 1.1092 - val_accuracy: 0.5537\n",
            "Epoch 14/20\n",
            "45/45 [==============================] - 86s 2s/step - loss: 0.5763 - accuracy: 0.7910 - val_loss: 1.4196 - val_accuracy: 0.5028\n",
            "Epoch 15/20\n",
            "45/45 [==============================] - 82s 2s/step - loss: 0.5172 - accuracy: 0.8008 - val_loss: 1.1697 - val_accuracy: 0.5537\n",
            "Epoch 16/20\n",
            "45/45 [==============================] - 73s 2s/step - loss: 0.4625 - accuracy: 0.8390 - val_loss: 1.3769 - val_accuracy: 0.5537\n",
            "Epoch 17/20\n",
            "45/45 [==============================] - 81s 2s/step - loss: 0.4726 - accuracy: 0.8305 - val_loss: 1.1007 - val_accuracy: 0.5819\n",
            "Epoch 18/20\n",
            "45/45 [==============================] - 74s 2s/step - loss: 0.4543 - accuracy: 0.8347 - val_loss: 1.1708 - val_accuracy: 0.5650\n",
            "Epoch 19/20\n",
            "45/45 [==============================] - 73s 2s/step - loss: 0.4406 - accuracy: 0.8263 - val_loss: 1.1534 - val_accuracy: 0.5311\n",
            "Epoch 20/20\n",
            "45/45 [==============================] - 73s 2s/step - loss: 0.5235 - accuracy: 0.7938 - val_loss: 1.1022 - val_accuracy: 0.5593\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "epochs=20\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-9texU0EhrGu",
        "outputId": "c3b30b02-f260-434d-a9ca-f7f5691de376"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-4c573b94d2ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
          ]
        }
      ],
      "source": [
        "def eval_model(model, X_test, Y_test):\n",
        "    score = model.evaluate(X_test, Y_test, verbose=1)\n",
        "    test_accuracy=print('Test accuracy:', score[1])\n",
        "    test_loss=print('Test loss:', score[0])\n",
        "    return test_loss, test_accuracy\n",
        "\n",
        "test_loss, test_accuracy = eval_model(model, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pQMSnqa_8cW6"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}